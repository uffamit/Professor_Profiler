# Professor Profiler üéì

A production-ready **multi-agent system** powered by **Google Gemini API** that analyzes exam papers to identify trends, classify questions, and generate personalized study recommendations.

## üåü Key Features

This project demonstrates **8+ key AI agent concepts** required for advanced agent systems:

### ‚úÖ 1. Multi-Agent System
- **Hub-and-Spoke Architecture**: Root orchestrator + 3 specialized sub-agents
- **Sequential Execution**: Taxonomist ‚Üí Trend Spotter ‚Üí Strategist workflow
- **Agent Delegation**: Root agent delegates specialized tasks to sub-agents
- **Parallel Processing**: Batch question classification (ready for parallel execution)

### ‚úÖ 2. Custom Tools & MCP Integration
- **PDF Reading Tool**: Extract text from exam papers using pypdf
- **Statistics Analysis Tool**: Compute frequency distributions and cognitive complexity
- **Visualization Tool**: Generate charts using matplotlib
- **Comparison Tool**: Analyze multiple exams for trends
- **MCP-Ready**: Extensible tool framework using FunctionTool wrapper

### ‚úÖ 3. Sessions & Memory Management
- **InMemorySessionService**: Persistent conversation state across interactions
- **Memory Bank**: Long-term storage for:
  - Historical exam analyses
  - Student preferences
  - Previous study plans
- **Context Compaction**: Smart summarization to manage token limits

### ‚úÖ 4. Observability
- **Structured Logging**: JSON logs with correlation IDs
- **Distributed Tracing**: Request flow tracking through agent hierarchy
- **Metrics Collection**: Performance counters for:
  - Agent execution time
  - Tool usage
  - Token consumption
  - Success/error rates

### ‚úÖ 5. Gemini API Integration
- **Real LLM Calls**: Full integration with Google Gemini 2.5
- **Tool Calling**: Native Gemini function calling support
- **Streaming Responses**: Async event-based execution
- **Model Selection**: Flash for classification, Pro for analysis

##  Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     USER QUERY                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ   Runner        ‚îÇ  ‚óÑ‚îÄ‚îÄ Session Service (Memory)
         ‚îÇ  (Orchestrator) ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ professor_profiler_agent ‚îÇ ‚óÑ‚îÄ‚îÄ Root Agent (Gemini 2.5 Pro)
    ‚îÇ (Hub)                    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ
            ‚îú‚îÄ‚îÄ‚îÄ Tools: read_pdf, analyze_stats, visualize, compare
            ‚îÇ
            ‚îú‚îÄ‚îÄ‚îÄ Sub-Agent 1: taxonomist (Flash)
            ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ Classifies questions by topic & Bloom's level
            ‚îÇ
            ‚îú‚îÄ‚îÄ‚îÄ Sub-Agent 2: trend_spotter (Pro)
            ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ Analyzes statistical shifts in exam patterns
            ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ Sub-Agent 3: strategist (Pro)
                 ‚îî‚îÄ‚îÄ‚îÄ Generates actionable study plans
```

## üöÄ Quick Start

### Prerequisites

- Python 3.10+
- Google AI API Key ([Get one here](https://makersuite.google.com/app/apikey))

### Installation

```bash
# Clone the repository
git clone https://github.com/uffamit/Professor_Profiler.git
cd Professor_Profiler

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set up your API key
export GOOGLE_API_KEY="your_gemini_api_key_here"
```

### Running the Demo

```bash
# Run comprehensive demo showcasing all features
python demo.py
```

### Running Tests

```bash
# Run integration tests
python tests/test_agent.py

# Or use pytest
pytest tests/
```

## üìã Usage Examples

### Basic Usage

```python
import asyncio
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
from profiler_agent.agent import root_agent
from google.genai import types as genai_types

async def analyze_exam():
    # Initialize session service
    session_service = InMemorySessionService()
    await session_service.create_session(
        app_name="professor_profiler",
        user_id="student_123",
        session_id="session_001"
    )
    
    # Create runner
    runner = Runner(
        agent=root_agent,
        app_name="professor_profiler",
        session_service=session_service
    )
    
    # Run analysis
    query = "Analyze physics_2024.pdf and tell me what to study"
    
    async for event in runner.run_async(
        user_id="student_123",
        session_id="session_001",
        new_message=genai_types.Content(
            role="user",
            parts=[genai_types.Part.from_text(text=query)]
        )
    ):
        if event.is_final_response():
            print(event.content.parts[0].text)

asyncio.run(analyze_exam())
```

### Using Memory Bank

```python
from profiler_agent.memory import MemoryBank

memory_bank = MemoryBank()

# Store exam analysis
memory_bank.add_memory(
    user_id="student_123",
    memory_type="exam_analysis",
    content={
        "exam": "Physics Midterm 2024",
        "topics": ["Quantum Mechanics", "Electromagnetism"],
        "difficulty": "high"
    },
    tags=["physics", "2024"]
)

# Retrieve memories
memories = memory_bank.get_memories("student_123", memory_type="exam_analysis")

# Search memories
results = memory_bank.search_memories("student_123", "quantum")

# Get compacted context for LLM
context = memory_bank.compact_context("student_123", max_tokens=500)
```

### Using Observability

```python
from profiler_agent.observability import setup_logging, metrics, tracer

# Setup structured logging
logger = setup_logging(level="INFO", structured=True)

# Start trace
trace_id = tracer.start_trace("exam_analysis", metadata={"user": "student_123"})

# Record metrics
metrics.increment("exams.analyzed")
metrics.histogram("processing.duration_ms", 1500.5)

# End trace
trace_data = tracer.end_trace(trace_id)

# Get all metrics
all_metrics = metrics.get_metrics()
```

## üèóÔ∏è Project Structure

```
Professor_Profiler/
‚îú‚îÄ‚îÄ google/adk/                  # Custom ADK framework
‚îÇ   ‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agent.py            # Agent implementation with Gemini integration
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ callback_context.py # Callback context for post-processing
‚îÇ   ‚îú‚îÄ‚îÄ runners/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ runner.py           # Agent execution runner
‚îÇ   ‚îú‚îÄ‚îÄ sessions/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ in_memory_session_service.py  # Session state management
‚îÇ   ‚îî‚îÄ‚îÄ tools/
‚îÇ       ‚îî‚îÄ‚îÄ function_tool.py    # Function tool wrapper
‚îÇ
‚îú‚îÄ‚îÄ profiler_agent/             # Main agent application
‚îÇ   ‚îú‚îÄ‚îÄ agent.py               # Root agent definition
‚îÇ   ‚îú‚îÄ‚îÄ config.py              # Configuration management
‚îÇ   ‚îú‚îÄ‚îÄ tools.py               # Custom tools (PDF, stats, viz)
‚îÇ   ‚îú‚îÄ‚îÄ memory.py              # Memory bank implementation
‚îÇ   ‚îú‚îÄ‚îÄ observability.py       # Logging, tracing, metrics
‚îÇ   ‚îú‚îÄ‚îÄ agent_utils.py         # Utility functions
‚îÇ   ‚îî‚îÄ‚îÄ sub_agents/            # Specialized sub-agents
‚îÇ       ‚îú‚îÄ‚îÄ taxonomist.py      # Question classification
‚îÇ       ‚îú‚îÄ‚îÄ trend_spotter.py   # Trend analysis
‚îÇ       ‚îî‚îÄ‚îÄ strategist.py      # Study plan generation
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_agent.py          # Integration tests
‚îÇ   ‚îî‚îÄ‚îÄ sample_data/           # Test data
‚îÇ
‚îú‚îÄ‚îÄ demo.py                    # Comprehensive demo script
‚îú‚îÄ‚îÄ requirements.txt           # Python dependencies
‚îú‚îÄ‚îÄ ARCHITECTURE.md            # Detailed architecture documentation
‚îî‚îÄ‚îÄ README.md                  # This file
```

## üîß Configuration

### Environment Variables

```bash
# Required: Google AI API Key
export GOOGLE_API_KEY="your_api_key"

# Optional: For Vertex AI
export GOOGLE_CLOUD_PROJECT="your_project_id"
export GOOGLE_CLOUD_LOCATION="global"
export GOOGLE_GENAI_USE_VERTEXAI="False"  # Set to "True" for Vertex AI
```

### Model Configuration

Edit `profiler_agent/config.py` to customize models:

```python
@dataclass
class ProfilerConfiguration:
    classifier_model: str = "gemini-2.0-flash-exp"  # Fast for classification
    analyzer_model: str = "gemini-2.0-flash-thinking-exp-01-21"      # Detailed for analysis
```

## üìä Agent Capabilities

### Taxonomist (Sub-Agent 1)
- **Purpose**: Classify questions by topic and cognitive level
- **Model**: gemini-2.0-flash-exp (optimized for speed)
- **Output**: Tagged questions with topics and Bloom's taxonomy levels
- **Bloom's Levels**: Remember, Understand, Apply, Analyze, Evaluate, Create

### Trend Spotter (Sub-Agent 2)
- **Purpose**: Identify statistical patterns across exams
- **Model**: gemini-2.0-flash-thinking-exp-01-21 (deep analysis)
- **Output**: Shift report showing:
  - Frequency shifts (topics appearing more/less)
  - Cognitive shifts (difficulty level changes)
  - Emerging patterns

### Strategist (Sub-Agent 3)
- **Purpose**: Generate actionable study recommendations
- **Model**: gemini-2.0-flash-thinking-exp-01-21
- **Output**: Study plan with:
  - **Hit List**: High-priority topics
  - **Safe Zone**: Well-covered topics  
  - **Drop List**: Low-value topics to skip

## üß™ Testing

### Run All Tests

```bash
python tests/test_agent.py
```

### Run Demo

```bash
python demo.py
```

The demo showcases:
1. Multi-agent system architecture
2. Custom tools execution
3. Observability features
4. Memory bank operations
5. Full agent workflow with mock or real API

## üìà Performance & Observability

### Metrics Tracked

- `exams.analyzed`: Counter of analyzed exams
- `questions.classified`: Number of classified questions
- `trends.identified`: Trends found per analysis
- `agent.execution.duration_ms`: Agent execution time
- `tool.invocation.count`: Tool usage statistics

### Logging Levels

- **INFO**: General operations (session creation, agent execution)
- **DEBUG**: Detailed execution flow (message additions, context updates)
- **WARNING**: Non-critical issues (missing API key, fallback behavior)
- **ERROR**: Failures (API errors, tool failures)

### Trace Data Structure

```json
{
  "trace_id": "uuid-here",
  "operation": "exam_analysis",
  "total_duration_ms": 1543.2,
  "spans": [
    {"name": "pdf_ingestion", "duration_ms": 120.5},
    {"name": "classification", "duration_ms": 450.2},
    {"name": "trend_analysis", "duration_ms": 680.1},
    {"name": "strategy_generation", "duration_ms": 292.4}
  ]
}
```

## üõ†Ô∏è Extending the System

### Adding a New Tool

```python
from google.adk.tools import FunctionTool

def my_custom_tool(param: str) -> dict:
    """
    Description of what the tool does.
    
    Args:
        param: Parameter description
    
    Returns:
        Dictionary with results
    """
    return {"result": "processed"}

# Add to agent
root_agent.tools.append(FunctionTool(func=my_custom_tool))
```

### Adding a New Sub-Agent

```python
from google.adk.agents import Agent
from profiler_agent.config import config

new_agent = Agent(
    name="my_agent",
    model=config.analyzer_model,
    description="What this agent does",
    instruction="Detailed instructions for the agent",
    output_key="agent_output"
)

# Add to root agent
root_agent.sub_agents.append(new_agent)
```

## üìù License

MIT License - See LICENSE file for details

## ü§ù Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Add tests for new features
4. Submit a pull request

## üìö Additional Resources

- [Google Gemini API Documentation](https://ai.google.dev/)
- [Agent Development Kit (ADK) Concepts](./ARCHITECTURE.md)
- [Bloom's Taxonomy Reference](https://cft.vanderbilt.edu/guides-sub-pages/blooms-taxonomy/)

## üéØ Roadmap

- [ ] Add evaluation metrics for agent performance
- [ ] Implement A2A (Agent-to-Agent) protocol
- [ ] Cloud deployment configurations (Cloud Run, Functions)
- [ ] Web interface with real-time updates
- [ ] Support for more document formats (DOCX, images)
- [ ] Vector database integration for semantic search
- [ ] Multi-language support

---

**Built with ‚ù§Ô∏è using Google Gemini AI**